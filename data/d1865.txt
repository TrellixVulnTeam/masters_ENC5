Anonymous social media users who fail to provide their ID should be blocked under the Government's duty of care plans to help curb online abuse, say MPs.

Social media firms should also face fines if they fail to prevent online abusers from setting up new accounts to continue harassing their victims, according to a committee of MPs.

The recommendation comes as the Government finalises its proposed new online harms Bill, due to be presented to Parliament this spring.

It follows petitions to Parliament backed by some 700,000 members of the public demanding verified ID be made a compulsory condition for opening a social media account. It included more than 500,000 who signed after racist abuse of England footballers after the 2020s Euros final at Wembley.

The petitions committee rejected compulsory ID verification because of the potential “chilling” effect it could have on minority communities or other vulnerable people.

Instead, it proposed that tech platforms should be required to give users the option to link their account to a form of verified ID on a voluntary basis. They would then also have an option to block communications with unverified accounts.

The MPs said this would reduce individuals’ potential exposure to abuse by screening out content posted by unverified accounts. “It would allow people to add an extra layer of protection to their online experience if they want it,” said the MPs.

The MPs said social media companies should face fines if they cannot demonstrate to Ofcom that they were successfully preventing people who have been banned from the platform for abusive behaviour from setting up new accounts.

Companies would be placed under a legal duty to show Ofcom that they had taken “proportionate” steps to protect adults from the risk of legal but harmful abuse on their platforms.

Duty of care laws to combat abuse should also be extended to smaller platforms rather than being solely focused on the major tech firms.

“The Bill should set a clear standard of protection adult users can expect against abuse on social media platforms, rather than leaving individual platforms to decide this in their rules on acceptable content,” said the MPs.

“It should also encourage companies to make changes to how their platforms work to reduce the risk of abuse occurring or being seen by large numbers of adult users in the first place.

“To achieve these outcomes, we recommend that the Government imposes a foundational general duty on platforms to protect their users from reasonably foreseeable risks of harm.”

Committee chairman Catherine McKinnell said: “Online abuse is a silent menace and this report sets out our recommendations to help tackle the enormous harm it causes, and ensure perpetrators face appropriate consequences for their actions.

“We spoke to students across the country who told us they felt that experiencing online abuse is simply a normal part of being online. This is incredibly alarming and highlights how important it is that we address this issue.”